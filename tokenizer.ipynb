{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the dependencies\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('punkt')\n",
    "# Initialize the stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 718715 entries, 0 to 718714\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   index          718715 non-null  int64 \n",
      " 1   body           718715 non-null  object\n",
      " 2   ticker_symbol  718715 non-null  object\n",
      " 3   date           718715 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 21.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1096868 entries, 0 to 1096867\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Unnamed: 0     1096868 non-null  int64 \n",
      " 1   body           1096868 non-null  object\n",
      " 2   ticker_symbol  1096868 non-null  object\n",
      " 3   date           1096868 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 33.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375711 entries, 0 to 375710\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Unnamed: 0     375711 non-null  int64 \n",
      " 1   body           375711 non-null  object\n",
      " 2   ticker_symbol  375711 non-null  object\n",
      " 3   date           375711 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 11.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 720138 entries, 0 to 720137\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Unnamed: 0     720138 non-null  int64 \n",
      " 1   body           720138 non-null  object\n",
      " 2   ticker_symbol  720138 non-null  object\n",
      " 3   date           720138 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 22.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1425013 entries, 0 to 1425012\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Unnamed: 0     1425013 non-null  int64 \n",
      " 1   body           1425013 non-null  object\n",
      " 2   ticker_symbol  1425013 non-null  object\n",
      " 3   date           1425013 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 43.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_amazon = pd.read_csv(\"data/amazon_token.csv\")\n",
    "display(tweets_amazon.info())\n",
    "\n",
    "tweets_tesla = pd.read_csv(\"data/tesla_token.csv\")\n",
    "display(tweets_tesla.info())\n",
    "\n",
    "tweets_microsoft = pd.read_csv(\"data/microsoft_token.csv\")\n",
    "display(tweets_microsoft.info())\n",
    "\n",
    "tweets_google = pd.read_csv(\"data/google_token.csv\")\n",
    "display(tweets_google.info())\n",
    "\n",
    "tweets_apple = pd.read_csv(\"data/apple_token.csv\")\n",
    "display(tweets_apple.info())\n",
    "\n",
    "# tweets_amazon\n",
    "# tweets_tesla\n",
    "# tweets_microsoft\n",
    "# tweets_google\n",
    "# tweets_apple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate to specific dates\n",
    "# date range 01-01-2015 through 2019-12-31\n",
    "\n",
    "\n",
    "initial_date = \"2019-01-01\"\n",
    "end_date = \"2019-12-31\"\n",
    "\n",
    "def date_span(df):\n",
    "\n",
    "    filtered = df[(df['date'] >= initial_date) & (df['date'] <= end_date)]\n",
    "\n",
    "    return (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 143439 entries, 575276 to 718714\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   index          143439 non-null  int64 \n",
      " 1   body           143439 non-null  object\n",
      " 2   ticker_symbol  143439 non-null  object\n",
      " 3   date           143439 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df = date_span(tweets_amazon)\n",
    "# tweets_df = date_span(tweets_tesla)\n",
    "# tweets_df = date_span(tweets_microsoft)\n",
    "# tweets_df = date_span(tweets_google)\n",
    "# tweets_df = date_span(tweets_apple)\n",
    "\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = tweets_df[\"body\"].to_list()\n",
    "# tweets_list[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of words\n",
    "\n",
    "words = []\n",
    "words_lists = [sentences.split() for sentences in tweets_list]\n",
    "\n",
    "for words_list in words_lists:\n",
    "    for word in words_list:\n",
    "        words.append(word)\n",
    "\n",
    "\n",
    "# print(words_lists[0])\n",
    "# words[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate hashtags from content\n",
    "tweet_tags = []\n",
    "tweet_content = []\n",
    "\n",
    "for word_string in words:\n",
    "    if word_string.startswith(\"#\") is True:\n",
    "        tweet_tags.append(word_string)\n",
    "    else:\n",
    "        tweet_content.append(word_string)\n",
    "        \n",
    "\n",
    "# print(tweet_tags[0:10])\n",
    "# print(tweet_content[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the lists \n",
    "#Import regex\n",
    "import re\n",
    "# Create a regex pattern to remove punctuation. \n",
    "\n",
    "def tokenizing (tweet_list):\n",
    "\n",
    "    pattern = r'[^a-zA-Z\\s ]'\n",
    "\n",
    "    # Create an empty list to hold the tokens.\n",
    "    tag_tokens = []\n",
    "    for tweet_word in tweet_list:\n",
    "        #tokens = re.findall(pattern, tweet_word)\n",
    "        tokens = re.sub(pattern, '', tweet_word)\n",
    "        tag_tokens.append(tokens)\n",
    "\n",
    "    return tag_tokens\n",
    "\n",
    "tokenized_hashtags = tokenizing(tweet_tags)\n",
    "tokenized_content = tokenizing(tweet_content)\n",
    "\n",
    "# print(\"Tokenized hashtags:\", tokenized_hashtags[0:15])\n",
    "# print(\"Tokenized content:\", tokenized_content[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords \n",
    "\n",
    "def remove_stopwords(tweets_list):\n",
    "    filtered_tokens = []\n",
    "        #for tweets in tweets_list:\n",
    "    filtered_token = [word for word in tweets_list if not word in stop_words]\n",
    "    # filtered_token = [word for word in tweets_list if word.lower() not in stop_words]\n",
    "        \n",
    "    filtered_tokens.append(filtered_token)\n",
    "        \n",
    "    # Display the filtered_tokens\n",
    "    return filtered_tokens\n",
    "\n",
    "filtered_hashtags = remove_stopwords(tokenized_hashtags)\n",
    "filtered_content = remove_stopwords(tokenized_content)\n",
    "\n",
    "# print(\"Tokenized hashtags:\", filtered_hashtags[0:6])\n",
    "# print(\"Tokenized content:\", filtered_content[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from the class activity for Create the bag-of-words\n",
    "def bag_words(filtered_list):\n",
    "    bag_of_words = {}\n",
    "    for i in range(len(filtered_list)):\n",
    "        for word in filtered_list[i]:\n",
    "            if word not in bag_of_words:\n",
    "                bag_of_words[word] = 0\n",
    "            bag_of_words[word] += 1\n",
    "\n",
    "    # Print the bag_of_words\n",
    "    return bag_of_words\n",
    "\n",
    "word_count_hashtags = bag_words(filtered_hashtags)\n",
    "word_count_content = bag_words(filtered_content)\n",
    "\n",
    "# print(word_count_hashtags)\n",
    "# word_count_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_keys = list(word_count_hashtags.keys())\n",
    "hashtag_values = list(word_count_hashtags.values())\n",
    "\n",
    "\n",
    "content_keys = list(word_count_content.keys())\n",
    "content_values = list(word_count_content.values())\n",
    "dates = initial_date + \" to \" + end_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_df = pd.DataFrame({\"Hashtag (#)\":hashtag_keys, \"Count\":hashtag_values})\n",
    "content_df = pd.DataFrame({\"Tweet\":content_keys, \"Count\":content_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "resorted_hashtags = hashtags_df.sort_values(by=[\"Count\"], ascending = False)\n",
    "resorted_content = content_df.sort_values(by=[\"Count\"], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "resorted_hashtags.reset_index(drop=True, inplace=True)\n",
    "resorted_hashtags.index += 1\n",
    "\n",
    "resorted_content.reset_index(drop=True, inplace=True)\n",
    "resorted_content.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: Amazon\n",
      "Ticker:AMZN\n",
      "Dates: 2019-01-01 to 2019-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag (#)</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stocks</td>\n",
       "      <td>7831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>investing</td>\n",
       "      <td>5253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stockmarket</td>\n",
       "      <td>5124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance</td>\n",
       "      <td>4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gold</td>\n",
       "      <td>3491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>silver</td>\n",
       "      <td>3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>options</td>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>commodities</td>\n",
       "      <td>2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trading</td>\n",
       "      <td>2331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hashtag (#)  Count\n",
       "1        stocks   7831\n",
       "2     investing   5253\n",
       "3   stockmarket   5124\n",
       "4       finance   4073\n",
       "5          gold   3491\n",
       "6        silver   3093\n",
       "7        Amazon   2856\n",
       "8       options   2479\n",
       "9   commodities   2449\n",
       "10      trading   2331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker = tweets_df[\"ticker_symbol\"].iloc[0]\n",
    "company = \"company\"\n",
    "\n",
    "if ticker == \"AMZN\":\n",
    "    company = \"Amazon\"\n",
    "elif ticker == \"AAPL\":\n",
    "    company = \"Apple\"\n",
    "elif ticker == \"MSFT\":\n",
    "    company = \"Microsoft\"\n",
    "elif ticker == \"GOOG\":\n",
    "    ticker = \"GOOG/GOOGL\"\n",
    "    company = \"Google\"\n",
    "else:\n",
    "    company = \"Tesla\"\n",
    "\n",
    "\n",
    "print(\"Company:\" + ' ' + company)\n",
    "print(\"Ticker:\" + ticker)\n",
    "print(\"Dates:\" + ' ' + initial_date + \" to \" + end_date)\n",
    "display(resorted_hashtags.head(10))\n",
    "\n",
    "resorted_hashtags.to_csv(\"data/\" + ticker + \"_hashtag_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: Amazon\n",
      "Ticker:AMZN\n",
      "Dates: 2019-01-01 to 2019-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>147611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>122108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>33860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FB</td>\n",
       "      <td>29165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>23873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>21881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SPY</td>\n",
       "      <td>19802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>17825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amzn</td>\n",
       "      <td>17771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>16917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet   Count\n",
       "1           147611\n",
       "2     AMZN  122108\n",
       "3     AAPL   33860\n",
       "4       FB   29165\n",
       "5     NFLX   23873\n",
       "6     TSLA   21881\n",
       "7      SPY   19802\n",
       "8    GOOGL   17825\n",
       "9     amzn   17771\n",
       "10  Amazon   16917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Company:\" + ' ' + company)\n",
    "print(\"Ticker:\" + ticker)\n",
    "print(\"Dates:\" + ' ' + initial_date + \" to \" + end_date)\n",
    "display(resorted_content.head(10))\n",
    "\n",
    "resorted_hashtags.to_csv(\"data/\" + ticker + \"_tweets_counts\" + initial_date + \"_\" + end_date + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activity Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original from class 21 activity 1 BoW_model_solution\n",
    "# # Import regex\n",
    "# import re\n",
    "# # Create a regex pattern to remove punctuation. \n",
    "# pattern = r'[^a-zA-Z\\s ]'\n",
    "\n",
    "# # Create an empty list to hold the tokens.\n",
    "# tokens = []\n",
    "\n",
    "# # Remove punctuation, tokenize sentence 1, and add the tokens to the tokens list.\n",
    "# sentence_1_cleaned = re.sub(pattern, '', sentence_1)\n",
    "# sentence_1_tokens = nltk.word_tokenize(sentence_1_cleaned.lower())\n",
    "# tokens.append(sentence_1_tokens)\n",
    "\n",
    "# # Remove punctuation, tokenize sentence 2, and add the tokens to the tokens list.\n",
    "# sentence_2_cleaned = re.sub(pattern, '', sentence_2)\n",
    "# sentence_2_tokens = nltk.word_tokenize(sentence_2_cleaned.lower())\n",
    "# tokens.append(sentence_2_tokens)\n",
    "\n",
    "# # Remove punctuation, tokenize sentence 3, and add the tokens to the tokens list.\n",
    "# sentence_3_cleaned = re.sub(pattern, '', sentence_3)\n",
    "# sentence_3_tokens = nltk.word_tokenize(sentence_3_cleaned.lower())\n",
    "# tokens.append(sentence_3_tokens)\n",
    "\n",
    "# # Display the tokens.\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove stopwords\n",
    "# filtered_tokens = []\n",
    "# for token in tokens:\n",
    "#     filtered_token = [word for word in token if not word in stop_words]\n",
    "#     filtered_tokens.append(filtered_token)\n",
    "    \n",
    "# # Diplay the filtered_tokens\n",
    "# filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the bag-of-words\n",
    "# bag_of_words = {}\n",
    "# for i in range(len(filtered_tokens)):\n",
    "#     for word in filtered_tokens[i]:\n",
    "#         if word not in bag_of_words:\n",
    "#             bag_of_words[word] = 0\n",
    "#         bag_of_words[word] += 1\n",
    "\n",
    "# # Print the bag_of_words\n",
    "# print(bag_of_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
